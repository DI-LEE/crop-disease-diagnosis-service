# crop-disease-diagnosis-service

crop disease diagnosis service application with image-captioning and object-detection(deep learning)



## :seedling:내 손안의 식물의사: 닥터 쑥쑥

> **딥러닝 기반 이미지 캡셔닝과 객체 인식을 이용한 작물 질병 진단 서비스**

# Team

## Team Logo

돋을볕

![image](https://user-images.githubusercontent.com/79498819/187262537-f8ac3650-fffe-4425-ac5f-44501b9c9349.png)


## Team Organization

| Name       | role                                                         | Contact                |
| ---------- | ------------------------------------------------------------ | ---------------------- |
| **이동인** | 팀장, 이미지캡셔닝 모델 구축 및 이식, 백엔드 서버 구축 보조, 시스템 구조 설계 | dongeen1@gmail.com     |
| 장승호     | 오브젝트 디텍션 모델 구축 및 데이터 증강, 앱 서비스 플로우 제작 | jason9865@naver.com    |
| 이지환     | 이미지 캡셔닝 모델 구축 및 모델 성능 비교연구, 앱 서비스 플로우 제작 | ywl9845@naver.com      |
| 류승기     | 벡엔드 로직 설계 및 구축, 프론트엔드 벡엔드 간 통신 및 연결, 서버 구축 및 모델 이식 | eukkki210@hufs.ac.kr   |
| 정훈서     | 오브젝트 디텍션 모델 구축 및 이식, 백엔드 서버 구축 보조, 시스템 구조 설계 | joel39809@gmail.com    |
| 오지환     | 데이터 수집 및 분석, 기획 및 발표                            | kmm8777@naver.com      |
| 양건안     | 프론트엔드 로직 설계 및 구축, 프론트엔드 백엔드 간 통신 및 연결, UX/UI 디자인 | dkddkr852@hufs.ac.kr   |
| 김재원     | 데이터 수집 및 분석, 기획 및 발표                            | jk243@st-andrews.ac.uk |

# Requirements

* `python==3.9`
* `tensorflow==2.8.0`
* `torch==1.12.1`
* `lutter==3.0.5 `
* `flask==2.2.2`

## Train environment

* `RTX 2070`

* `CUDA Version==11.2`
* `cuddn==7.6.5`

# Keywords

* Image-captioning
* Object-detection
* Natural Language Generation
* diagnosis of crop disease
* Home farming

# Motivation & Purpose

 도시농업에 대한 관심도가 매년 꾸준히 증가하고 있다. 위메프 제공 자료에 따르면 도시농부 수는 2010년 15만명에서 2020년 185만명으로 10년 만에 10배나 증가했다. 특히 최근 물가상승의 여파로 식자재값이 급등하여 농작물을 구매하지 않고 직접 집에서 키워 섭취하는 ‘홈파밍’ 문화가 확산되고 있다. 이처럼 도시의 가정에서 직접 작물을 길러 소비하는 도시농업 시장이 꾸준히 증가하고 있지만, 도시농부들은 대체로 전문 농업인이 아닌 새내기 농부가 많아 영농기술 및 농업 경험 부족으로 농작물의 질병을 제때 진단하지 못해 적절한 치료법으로 작물을 관리하지 못하고 결국 수확에 실패한 사례를 어렵지 않게 찾아볼 수 있다. 따라서 도시농부의 작물 관리를 돕기 위해 작물의 상태를 자세하게 묘사하고 해당 질병을 진단하는 앱 서비스를 개발하게 되었다.

# Development Goals

 도시농부 등 농업에 익숙하지 않은 초보 농부를 대상으로 한 작물 관리 앱을 개발하고자 했다. 질병에 감염된 것으로 의심되는 작물의 사진을 찍으면 인공지능 딥러닝 기술 기반의 모델을 거쳐 감염 환부를 바운딩 박스로 표시하고 환부에 대한 자세한 묘사와 함께 해당 질병을 진단하는 문장을 생성하도록 했다. 단순히 어떤 질병에 걸렸는지만 알려주는 것이 아니라 질병 감염 부위를 표시하고 감염 부위를 자세하게 묘사하여 질병 진단에 대한 명확한 근거를 제시할 수 있다. 또한 질병 자체를 진단함으로써 해당 질병에 감염될 수 있는 모든 작물에 대한 질병 진단을 가능하게 하여 작물별로 병을 진단하는 번거로움을 해소할 수 있도록 했다. 또한 진단의 정확도를 높이기 위해 정상적인 상태의 작물 사진이나 작물이 아닌 물체의 사진을 입력했을 때 질병이 진단되지 않도록 추가 데이터를 구축하여 모델을 학습시켰다. 감염된 작물의 질병이 진단되면 해당 질병의 발생 환경과 관리법을 소개하여 질병을 치료하고 예방하는 방법을 쉽게 알려주도록 했다.

# System structure

![image01](https://user-images.githubusercontent.com/79498819/187089936-ba228c58-8ce3-4b16-90d5-0c24486f8db9.png)


# Service flow

 ![image02](https://user-images.githubusercontent.com/79498819/187089950-e65cf190-7c8c-419e-b19c-5fd9fa26903a.png)

# Disease diagnostic results

![image03](https://user-images.githubusercontent.com/79498819/187089977-b11bf678-b958-42c0-b732-a9dd111652b6.png)

# Project flow

![image04](https://user-images.githubusercontent.com/79498819/187089985-d92a5ede-9499-4953-8d5c-bec32b1c17cc.png)

# Deep learning

## Data Collection and Labeling

 작물 이미지 데이터로는 AI-hub에 오픈소스로 공개되어 있는 ‘노지작물 질병 진단 이미지’ 데이터셋을 사용했다. 해당 이미지 데이터셋에는 정상적인 작물 이미지와 질병에 걸린 작물 이미지가 골고루 들어있어 학습용 데이터로 적합하다는 판단을 내렸다. 전체 이미지 데이터셋에서 ‘고추’, ‘애호박’, ‘토마토’, ‘콩’, ‘파’ 등 총 5개의 작물을 선별한 이미지 데이터를 추출하여 총 9개의 질병을 탐지하고자 했다. 또한 각 질병의 특징과 중증도를 구분하여 질병의 특징을 묘사하는 캡션 문장 데이터를 구축했다. 이미지 캡셔닝 모델 학습에는 총 123,913개의 이미지와 619,565개의 캡션을 사용했으며 오브젝트 디텍션 모델 학습에는 총 31,394개의 이미지를 사용했다.

## Modeling

### Image Captioning

 이미지 캡셔닝(Image Captioning)은 이미지를 설명하는 문장을 생성하는 기술로, 이미지의 여러 가지 특징을 자세히 묘사한 문장을 생성한다. 프로젝트에 사용된 이미지 캡셔닝 모델은 자연어처리의 기계번역 매커니즘 중 하나인 ‘인코더-디코더 형식’을 사용한다. 인코더에서 이미지의 특징을 추출하고 디코더에서는 인코더에서 추출된 특징을 바탕으로 캡션 문장을 생성한다. 우리의 이미지 캡셔닝 모델의 인코더에는 이미지 처리에 자주 사용되는 CNN 모델을 사용하는데 그중 ‘ImageNet’이라는 이미지 데이터로 사전학습을 거친 InceptionV3 모델을 사용하여 이미지에서 특징을 추출한다. 그리고 디코더에는 자연어를 생성해내는 Language Model(언어 모델)을 사용하는데 그중 RNN 모델을 사용하지 않고도 여러 번의 ‘Self-Attention’ 방식으로 문장 생성 성능을 획기적으로 향상시킨 ‘Transformer’ 모델을 사용했다. 

  이미지가 CNN계열의 InceptionV3 에 입력되면 모델은 이미지에서 여러 특징을 분석한다. 가령 잎의 가장자리에 노란 점박이가 생긴 모습, 잎의 색상 등을 분석하게 된다. 분석된 특징은 Transformer 모델에 입력된다. Transformer 모델도 인코더-디코더 구조를 지니는데, 우선 이미지의 특징은 각 특징의 위치 정보와 함께 Transformer의 인코더에 입력되어 Self-Attention 과정을 거쳐 분석된 뒤 Transformer의 디코더에 입력된다. 또한 Transformer의 디코더에는 해당 이미지에 대한 정답 레이블, 즉, 실제 캡션 문장도 함께 입력되는데 이때 Transformer의 인코더에서 분석된 이미지 특징과 디코더에 입력된 실제 캡션 문장을 Self-Attention 과정으로 종합적으로 분석하여 최종적으로 Transformer 디코더에서 해당 이미지에 대해 모델이 예측한 캡션 문장이 생성된다.

### Object Detection

 객체탐지(object-detection)은 한 이미지에서 객체와 그 경계 상자(bounding box)를 탐지하는 기술이다. 객체 탐지 알고리즘은 일반적으로 이미지를 입력으로 받고, 경계 상자와 객체 클래스 리스트를 출력하며 이때 경계 상자에 대응하는 예측 클래스와 클래스의 신뢰도(confidence)를 출력한다. 2012년 이전까지는 non-neural network-based방식이 쓰이다가 2012년을 기점으로 neural network-based 기법이 활발히 연구되었다. 이 중 우리가 사용한 모델은 2018년에 출시된 Yolo 모델이다. 2022년 현재까지 v7까지 출시되었으며 v5부터는 PyTorch를 기반으로 구현되었기 때문에 파이썬 환경에서도 효과적으로 사용할 수 있게 되었다. 우리 조는 뛰어난 성능과 많은 참고문헌을 확보할 수 있는 Yolov5를 모델을 활용하였다. 

  모델을 본격적으로 구축하기 전에 데이터 수집을 진행하였다. 이미지 캡셔닝과 마찬가지로 AI-hub의 노지 작물 질병 진단 이미지 데이터셋과 시설 작물 질병 진단 데이터셋을 활용하였으며 고추, 애호박, 토마토, 콩, 파 등 총 5개의 작물에서 9개의 질병을 탐지하는 것을 목표로 하였다. 다만 흰가루병과 잎마름병은 2개의 작물에서 동시에 등장하는 질병이었기 때문에 실제 예측 클래스는 7개로 지정하였다.

  데이터 수집과 예측 클래스를 지정한 후 데이터 라벨링을 진행하였다. LabelImg라는 툴을 다운로드하고 작물 환부에 바운딩 박스(Bounding Box)를 만들었다.

활용할 수 있는 원천 데이터 사진은 6,000여 장이었는데, 모델을 학습시키기에는 충분하지 않은 양이었기 때문에 데이터 증강을 실시하였다. 파이썬 개발환경에서 ‘imgaug’패키지를 활용하여 증강 코드를 만들었고, 그 결과 train 25,458장, valid 5,936장, 총 31,394장의 이미지 데이터셋을 구축하는데 성공했다. 아울러 개별 이미지의 크기를 640 * 640으로 크기를 줄이는 작업도 실시하였다. 

  이후 Yolov5 사전 모델을 다운로드하여 학습을 진행하였다. Yolov5에서 제공하는 사전 훈련 모델은 Yolov5n, Yolov5s, Yolov5m, Yolov5l, Yolov5x 총 5개이다. n에서 x로 갈수록 모델의 성능은 좋아지지만, 학습시키는데 더 많은 시간이 소요된다. 우리 조는 학습의 성능과 학습 시간을 적절히 고려하여 Yolov5m모델을 채택하여 학습을 시켰고 15시간에 걸친 끝에 모델 구축에 성공했다.

# APP

 앱 프론트엔드 개발에는 구글에서 제공하는 Dart 언어기반의 무료 프레임워크인 ‘flutter’을 사용했으며 백엔드 개발에는 python 언어 기반 웹 프레임워크인 ‘flask’를 사용했다. 서버는 안정적이고 탄력성있는 성능으로 유명한 ‘AWS EC2’를 사용했으며 앱 UX/UI 디자인과 앱 서비스 플로우는 협업 디자인 툴인 ‘Figma’를 사용했다.

## Frontend

 애플리케이션 이름인 ‘Dr.쑥쑥’은 식물의 질병을 진단하는 ‘식물 의사’의 뜻을 내포하고 있다. 식물 의사라는 컨셉에 맞게 전체적으로 그린 파스텔 톤을 사용하여 디자인했고 누구나 사용하기 쉽게 심플한 UX/UI로 화면을 구성했다. 그리고 프론트엔드 부분에서 기존에 기획했던 카메라, 날씨, 질병 진단, 그리고 방제 방법 제공 기능을 구현했다. 카메라 기능은 flutter에서 제공하는 ‘image_picker’ 패키지를 이용해 구현했고 날씨와 질병 진단 기능은 서버와 클라이언트의 API 통신을 통해 서비스에 필요한 데이터를 받아 앱 화면에 출력하는 방식으로 구현하였다. 마지막으로 질병에 따라 서로 다른 방제 방법을 소개하는 페이지로 이동할 수 있도록 앱을 구현했다.

## Backend & Server

먼저 개발 환경 구축이 중요하다고 생각했기에 이에 필요한 각 패키지와 라이브러리 등의 버전을 통일하고 공유하는 과정에 충분한 시간을 투자했다.

 이후 프론트엔드와 연동하는데 필요한 API를 설계하기 위해 직접 구조도를 그려보고 구체화하면서 핵심 백엔드 코드를 작성하였다.

 이미지 캡셔닝 모델과 오브젝트 디텍션 모델이 완성된 이후에는 사전에 구축된 백엔드 서버에 두 모델을 이식하는데 많은 공을 들였다. 두 모델을 한 화면에 동시에 보여줘야 했기 때문에 로직 구성 단계에서 고려해야 할 것들이 많았고, 결국 프론트엔드에서 전달된 사진을 저장하여 두 모델의 결과물인 캡션과 디텍션된 사진을 한 번에 프론트엔드로 전달하는 로직으로 모델 이식을 완료하였다.

 이 과정에서 ‘AWS EC2’에서 무료로 사용할 수 있는 인스턴스 유형의 CPU(1GB)/메모리(RAM 1GB) 한계와 우리가 제작한 모델의 용량 문제로 인해 서버에 과부하가 일어나는 문제가 발생하였고, 이를 해결하기 위하여 ‘AWS EC2’의 하드디스크의 일부 용량을 swap memory로 할당하였다. 이 과정을 통해 메모리에 여유를 주고, 서버의 부담이 줄어들면서 서버가 안정화되는 효과를 얻을 수 있었다.

# expectation effectiveness

 먼저 농업에 대한 이미지를 개선할 수 있다. 전문적인 관리 지식이 요구된다는 인식을 개선하여 농업에 대한 접근성을 향상할 수 있다. 

 두 번째로 여러 부가 서비스를 통해 새내기 농부와 베테랑 농부의 가교역할을 할 수 있다. 질병이 발생하는 환경과 질병 예방법을 짧은 문장으로 소개하여 앞으로 해당 질병을 예방하기 위한 환경과 예방 방법을 쉽게 파악할 수 있도록 한다. 

 마지막으로 농업 및 원예 시장의 발전에 영향을 줄 수 있다. 질병 진단의 대상을 더 많은 농작물로 확대할 수 있고 더 나아가 해당 질병에 걸릴 수 있는 반려 식물로도 확대할 수 있다. 이처럼 더 많은 종류의 식물에 대한 질병을 진단할 수 있는 방향으로 서비스를 발전시켜 많은 사람이 식물 관리 서비스를 이용하도록 하고 궁극적으로 농업 및 원예 시장의 규모를 확대할 수 있을 것으로 기대된다.

# References

Xu et al. "Show, attend and tell: Neural image caption generation with visual attention.", *International conference on machine learning*. PMLR, 2015.


Li et al. “Entangled Transformer for Image Captioning”, *Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)*, 2019.


Taraneh et al. “Deep Learning Approaches on Image Captioning: A Review”, *arXiv preprint arXiv:2201.12944*, 2022.

